---
**Technical Report**

**Project Title:** Mean Teacher-Guided CTO-Net for Boundary-Aware Lymphatic Vessel Segmentation
**Authors:** Lê Hoàng Chí Vĩ (2353336), Vũ Hải Tuấn (2353280)
**Course:** Programming Intergration Project (CO3101)
**Instructor:** Ph.D Nguyễn An Khương
**Date:** December 2025

---

**Presentation Video:** [Link to your 30-minute presentation video will be here]

---

### **Abstract**

Medical image segmentation is a critical task that often suffers from a scarcity of labeled data. This project addresses the challenge of segmenting lymphatic vessels by developing a robust, semi-supervised learning pipeline. We propose a two-stage training strategy centered on **CTO-Net**, a custom segmentation model with a Res2Net-50 backbone. Stage 1 trains a baseline model on a small, fully-annotated dataset. Stage 2 refines this model using the **Mean Teacher** method, which leverages a large corpus of unlabeled video frames to improve generalization and prediction consistency. Our results demonstrate a significant improvement in segmentation quality from the baseline to the final model, validating the effectiveness of the semi-supervised approach. The project delivers an end-to-end solution, including data processing scripts, a flexible training framework, and an interactive GUI for results analysis.

---

### **1. Introduction**

The accurate segmentation of lymphatic vessels from medical imagery is essential for clinical diagnosis and research. However, the process of manually annotating these intricate structures is time-consuming, expensive, and requires domain expertise, leading to a bottleneck in the development of fully supervised deep learning models.

This project tackles this problem by proposing a **semi-supervised learning (SSL)** pipeline that reduces the dependency on labeled data. Our core objective was to build a system that could learn from a small set of annotated images and a large pool of unlabeled video data to produce high-quality vessel segmentations.

The proposed solution is a two-stage pipeline:
1.  **Supervised Baseline:** A CTO-Net model is first trained on the limited labeled dataset to establish a functional baseline.
2.  **Semi-Supervised Refinement:** The baseline model is then refined using the Mean Teacher method, where a "student" model learns from the pseudo-labels generated by a "teacher" model on unlabeled data.

This report details the project's methodology, implementation, experimental results, and key learnings.

---

### **2. Project Background and Team Contribution**

This work is a direct continuation of the project **"Deep learning in Medical Researches: Lymphatic Vessel Segmentation"**, which established a fully supervised pipeline for this task. Our project extends this foundation by integrating a semi-supervised learning paradigm to reduce the dependency on manually annotated data.

The interactive GUI application (`app.py`) was originally developed by **Vũ Hoàng Tùng** as part of the foundational project, and we have adapted it for our new pipeline. We extend our sincere gratitude for this significant contribution.

The project was a collaborative effort with the following task division:

| Member Name              | Student ID | Primary Responsibilities                                                                                                                               |
| ------------------------ | ---------- | ------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **Vũ Hải Tuấn**          | 2353280    | <ul><li>Led the implementation and training of the core model architectures: **CTO-Net** and the experimental **CTO Stitch-ViT**.</li><li>Developed the supervised training pipeline (Stage 1).</li></ul> |
| **Lê Hoàng Chí Vĩ**      | 2353336    | <ul><li>Led the implementation and refinement of the semi-supervised learning pipeline (Stage 2) using the **Mean Teacher** algorithm.</li><li>Developed data processing and results visualization scripts.</li></ul> |

**Joint Contributions (Lê Hoàng Chí Vĩ & Vũ Hải Tuấn):**
*   Design and tuning of the composite loss function (BCE, Dice, and Boundary Loss).
*   Analysis of experimental results to identify model strengths and weaknesses.
*   Preparation of the final report, documentation, and presentation.

---

### **3. Dataset**

#### **3.1. Data Source and Content**
All data used in this project was provided by the lab of researcher **Lê Quỳnh Trâm**. The data consists of video recordings of lymphatic vessels in two different contexts: Human and Rat tissue. Crucially, **Lê Quỳnh Trâm** also performed all manual annotations for the labeled data, providing the ground truth for our supervised training.

#### **3.2. Data Statistics**

| Dataset | Labeled Data        | Unlabeled Data                                    |
| ------- | ------------------- | ------------------------------------------------- |
| **Human** | 33 annotated images | 3 videos (processed into thousands of frames)     |
| **Rat**   | 33 annotated images | 8 videos (processed into thousands of frames)     |

#### **3.3. Pre-processing Pipeline**
A preparatory pipeline was developed to convert the raw data into a format suitable for training:
1.  **Mask Generation:** The labeled data, provided as images with accompanying `.json` files (containing polygon coordinates), were processed to generate binary segmentation masks.
2.  **Frame Extraction:** For the unlabeled data, frames were extracted from the source videos at a specified rate (e.g., 1 frame per second) to create a large dataset for the semi-supervised learning stage.

---

### **4. Methodology**

#### **4.1. Overall Pipeline**
Our methodology is a two-stage process designed to maximize learning from limited annotations.

![Pipeline Diagram](cto_vanilla_pipeline.jfif)
*Figure 1: The two-stage training pipeline.*

1.  **Stage 1: Supervised Baseline Training:** The CTO-Net model is trained exclusively on the 33 labeled images. The loss is computed only on these images. The resulting model serves as the baseline and the starting point for the next stage.
2.  **Stage 2: Semi-Supervised Refinement:** The weights from the baseline model are loaded into two identical models: the "student" and the "teacher". In each training iteration, the student is trained on both labeled images (with a supervised loss) and unlabeled images (with a consistency loss). The teacher's weights are updated using an Exponential Moving Average (EMA) of the student's weights. This process encourages the student to produce consistent and accurate predictions on the unlabeled data.

#### **4.2. Model Architecture**
The primary model is **CTO-Net**, a custom U-Net-like architecture.
-   **Backbone:** We use **Res2Net-50** as the encoder. Res2Net enhances the standard ResNet by constructing hierarchical residual-like connections within a single residual block, allowing it to represent features at multiple scales.
-   **Decoder:** The decoder consists of several upsampling blocks that progressively reconstruct the segmentation mask.
-   **Experimental Variant (CTO Stitch-ViT):** We also developed an experimental model that incorporates Vision Transformer (ViT) blocks into the decoder. The goal is to leverage the self-attention mechanism to better capture global context, which is potentially beneficial for segmenting long, continuous vessel structures.

#### **4.3. Semi-Supervised Learning: The Mean Teacher Method**
The Mean Teacher method is a powerful SSL technique.
-   **Student Model:** The primary model that is actively trained via gradient descent.
-   **Teacher Model:** A model with the same architecture as the student. Its weights are not trained directly but are an EMA of the student's weights. This makes the teacher's predictions more stable over time.
-   **Consistency Loss:** The student is encouraged to produce predictions on unlabeled data that are consistent with the teacher's predictions. We use a Mean Squared Error (MSE) loss between the student's and teacher's output masks for unlabeled samples.

#### **4.4. Loss Functions**
The total loss for the student model is a weighted sum of three components:
1.  **Binary Cross-Entropy (BCE) Loss:** A standard loss for binary classification tasks.
2.  **Dice Loss:** Directly optimizes the Dice Score (F1-score), which is a common metric for segmentation tasks as it is robust to class imbalance.
3.  **Boundary Loss:** A custom loss term that penalizes errors at the boundaries of the vessels. This encourages the model to produce sharper and more precise edges.

---

### **5. Implementation Details**

#### **5.1. Project Structure**
The codebase is organized into modules for clarity and maintainability.
```text
.
├── app.py              # GUI Application
├── config_stage1.json  # Configuration for Stage 1
├── data/               # All project data
├── logs/               # Training logs, curves, and images
├── models/             # Saved model checkpoints
└── src/                # Python source code
    ├── main.py         # Main training script
    ├── config.py       # Handles configuration loading
    ├── models/         # Model definitions (cto, cto_stitchvit)
    ├── training/       # Training logic (trainer, losses, mean_teacher)
    └── utils/          # Utility modules (metrics, logging, etc.)
```

#### **5.2. Software & Libraries Used**
- Python 3.9+
- PyTorch
- OpenCV
- Scikit-learn
- PyQt5 (for the GUI)
- Key libraries are listed in `requirements.txt`.

---

### **6. Experimental Results and Analysis**

#### **6.1. Evaluation Metrics**
Performance was measured using Dice Score, Intersection over Union (IoU), Precision, and Recall.

#### **6.2. Training Performance**
The training curves for the CTO-Net model on the Human dataset show clear convergence and the benefit of Stage 2.

**Stage 1 vs. Stage 2 Training Curves:**
![Baseline Curves](logs/Human/cto/Human_20251122_234019_detailed_curves.png)
![Final Curves](logs/Human/cto/Human_20251123_000145_detailed_curves.png)
*Figure 2: Dice and Loss curves for Stage 1 (left) and Stage 2 (right). Stage 2 shows continued stability and learning on a much larger dataset.*

#### **6.3. Segmentation Quality**
Visual comparison reveals a dramatic improvement in segmentation quality after the semi-supervised stage.

**Prediction Comparison:**
![Baseline Predictions](logs/Human/cto/baseline_predictions.png)
![Final Predictions](logs/Human/cto/final_predictions.png)
*Figure 3: Predictions from the Stage 1 baseline model (top) vs. the Stage 2 final model (bottom). The final model produces significantly cleaner and more coherent segmentations.*

**Analysis:** The baseline model, trained only on labeled data, correctly identifies major vessel structures but produces noisy, disconnected predictions. The final model, refined with unlabeled data, generates smooth, confident, and structurally complete masks. This demonstrates that the model successfully learned the underlying anatomical structure from the unlabeled video frames.

---

### **7. Discussion**

#### **7.1. Project Successes**
1.  **Effective SSL:** The Mean Teacher pipeline successfully leveraged unlabeled data to significantly improve segmentation quality, validating the core hypothesis of this project.
2.  **High-Quality Segmentation:** The custom CTO-Net model with its Res2Net backbone and boundary-aware loss proved effective for this specific task.
3.  **End-to-End Pipeline:** The project resulted in a complete, usable system, from data preparation to interactive analysis.

#### **7.2. Limitations and Future Work**
1.  **Experimental Stitch-ViT:** The `cto_stitchvit` model is a preliminary exploration. More rigorous hyperparameter tuning and architectural adjustments are needed to determine if the added complexity of the transformer blocks provides a tangible benefit. Future work could explore more advanced ViT integrations.
2.  **Dependence on Pseudo-Labels:** The SSL stage relies on high-quality pseudo-labels from the teacher. If the initial baseline model is very poor, or if there is a large domain gap between labeled and unlabeled sets, the SSL training could be unstable. Future work could incorporate techniques to filter or weight pseudo-labels based on confidence.
3.  **Computational Cost:** The two-stage process is computationally intensive. Research into more efficient SSL methods or model distillation could reduce training time.

---

### **8. Key Learnings**
This project provided valuable hands-on experience in several key areas:
1.  **Semi-Supervised Learning:** Gained a deep, practical understanding of the Mean Teacher method, including implementing consistency loss and Exponential Moving Average (EMA) updates.
2.  **Advanced Model Architecture:** Learned to implement and integrate complex architectures like Res2Net and experiment with hybrid models involving Vision Transformers.
3.  **Loss Function Engineering:** Acquired experience in designing and balancing a composite loss function to optimize for specific segmentation characteristics.
4.  **Building a Full ML Pipeline:** Developed skills in creating an end-to-end workflow, from data preprocessing and training to building an interactive application.
5.  **Reproducibility:** Learned the importance of structured code, clear documentation, and external configuration files to ensure experiments are reproducible and extensible.

---

### **9. Conclusion**
This project successfully developed and validated a semi-supervised pipeline for lymphatic vessel segmentation. By combining a strong baseline architecture (CTO-Net) with the Mean Teacher method, we were able to leverage unlabeled video data to overcome the limitations of a small annotated dataset, producing high-quality segmentation masks. The final system is an effective end-to-end solution that demonstrates the power of semi-supervised learning for medical imaging tasks.

---

### **10. Appendix: How to Run the Project**
1.  **Setup:**
    ```bash
    # Create and activate a virtual environment
    python -m venv venv && source venv/bin/activate
    # Install dependencies
    pip install -r requirements.txt
    ```
2.  **Data Preparation:**
    - Place labeled data in `data/annotated/<type>/` and unlabeled videos in `data/video/<type>/`.
    - Run `tools/scripts/convert_json_to_mask.py` and `tools/scripts/extract_frames.py`.
3.  **Training:**
    ```bash
    # Run the full pipeline for the default CTO-Net
    python -m src.main all --visualize
    ```
4.  **Launch GUI:**
    ```bash
    python app.py
    ```
