---
**Technical Report**

**Project Title:** Mean Teacher-Guided CTO-Net for Boundary-Aware Lymphatic Vessel Segmentation
**Authors:** Lê Hoàng Chí Vĩ (2353336), Vũ Hải Tuấn (2353280)
**Course:** Programming Intergration Project (CO3101)
**Instructor:** Ph.D Nguyễn An Khương
**Date:** December 2025

---

**Presentation Video:** [Link to your 30-minute presentation video will be here]

**Project Resources (Dataset, Models, Results):** [Google Drive Link](https://drive.google.com/drive/folders/1ORzUm1P5PK35O_L4YQ2L_IgIZZbkXi-0)

---

### **Abstract**

Medical image segmentation is a critical task that often suffers from a scarcity of labeled data. This project addresses the challenge of segmenting lymphatic vessels by developing a robust, semi-supervised learning pipeline. We propose a two-stage training strategy centered on **CTO-Net**, a custom segmentation model with a Res2Net-50 backbone. Stage 1 trains a baseline model on a small, fully-annotated dataset. Stage 2 refines this model using the **Mean Teacher** method, which leverages a large corpus of unlabeled video frames to improve generalization and prediction consistency. Our results demonstrate a significant improvement in segmentation quality from the baseline to the final model, validating the effectiveness of the semi-supervised approach. The project delivers an end-to-end solution, including data processing scripts, a flexible training framework, and an interactive GUI for results analysis.

---

### **1. Introduction**

The accurate segmentation of lymphatic vessels from medical imagery is essential for clinical diagnosis and research. However, the process of manually annotating these intricate structures is time-consuming, expensive, and requires domain expertise, leading to a bottleneck in the development of fully supervised deep learning models.

This project tackles this problem by proposing a **semi-supervised learning (SSL)** pipeline that reduces the dependency on labeled data. Our core objective was to build a system that could learn from a small set of annotated images and a large pool of unlabeled video data to produce high-quality vessel segmentations.

The proposed solution is a two-stage pipeline:
1.  **Supervised Baseline:** A CTO-Net model is first trained on the limited labeled dataset to establish a functional baseline.
2.  **Semi-Supervised Refinement:** The baseline model is then refined using the Mean Teacher method, where a "student" model learns from the pseudo-labels generated by a "teacher" model on unlabeled data.

This report details the project's methodology, implementation, experimental results, and key learnings.

---

### **2. Project Background and Team Contribution**

This work is a direct continuation of the project **"Deep learning in Medical Researches: Lymphatic Vessel Segmentation"** ([Original Repository](https://github.com/TUng1872004/Lymphatic-vessel)), which established a fully supervised pipeline for this task. Our project extends this foundation by integrating a semi-supervised learning paradigm to reduce the dependency on manually annotated data.

The interactive GUI application (`app.py`) was originally developed by **Vũ Hoàng Tùng** as part of the foundational project, and we have adapted it for our new pipeline. We extend our sincere gratitude for this significant contribution.

The project was a collaborative effort with the following task division:

| Member Name              | Student ID | Primary Responsibilities                                                                                                                               |
| ------------------------ | ---------- | ------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **Vũ Hải Tuấn**          | 2353280    | <ul><li>Led the implementation and training of the core model architectures: **CTO-Net** and the experimental **CTO Stitch-ViT**.</li><li>Developed the supervised training pipeline (Stage 1).</li></ul> |
| **Lê Hoàng Chí Vĩ**      | 2353336    | <ul><li>Led the implementation and refinement of the semi-supervised learning pipeline (Stage 2) using the **Mean Teacher** algorithm.</li><li>Developed data processing and results visualization scripts.</li></ul> |

**Joint Contributions (Lê Hoàng Chí Vĩ & Vũ Hải Tuấn):**
*   Design and tuning of the composite loss function (BCE, Dice, and Boundary Loss).
*   Analysis of experimental results to identify model strengths and weaknesses.
*   Preparation of the final report, documentation, and presentation.

---

### **3. Dataset**

#### **3.1. Data Source and Content**
All data used in this project was provided by the lab of researcher **Lê Quỳnh Trâm**. The data consists of video recordings of lymphatic vessels in two different contexts: Human and Rat tissue. Crucially, **Lê Quỳnh Trâm** also performed all manual annotations for the labeled data, providing the ground truth for our supervised training.

#### **3.2. Data Statistics**

| Dataset | Labeled Data        | Unlabeled Data                                    |
| ------- | ------------------- | ------------------------------------------------- |
| **Human** | 33 annotated images | 3 videos (processed into thousands of frames)     |
| **Rat**   | 33 annotated images | 8 videos (processed into thousands of frames)     |

#### **3.3. Pre-processing Pipeline**
A preparatory pipeline was developed to convert the raw data into a format suitable for training:
1.  **Mask Generation:** The labeled data, provided as images with accompanying `.json` files (containing polygon coordinates), were processed to generate binary segmentation masks.
2.  **Frame Extraction:** For the unlabeled data, frames were extracted from the source videos at a specified rate (e.g., 1 frame per second) to create a large dataset for the semi-supervised learning stage.

---

### **4. Methodology**

#### **4.1. Overall Pipeline**
Our methodology is a two-stage process designed to maximize learning from limited annotations.

![Pipeline Diagram](cto_vanilla_pipeline.jfif)
*Figure 1: The two-stage training pipeline.*

1.  **Stage 1: Supervised Baseline Training:** The CTO-Net model is trained exclusively on the 33 labeled images. The loss is computed only on these images. The resulting model serves as the baseline and the starting point for the next stage.
2.  **Stage 2: Semi-Supervised Refinement:** The weights from the baseline model are loaded into two identical models: the "student" and the "teacher". In each training iteration, the student is trained on both labeled images (with a supervised loss) and unlabeled images (with a consistency loss). The teacher's weights are updated using an Exponential Moving Average (EMA) of the student's weights. This process encourages the student to produce consistent and accurate predictions on the unlabeled data.

#### **4.2. Model Architecture**
The primary model is **CTO-Net**, a custom U-Net-like architecture.
-   **Backbone:** We use **Res2Net-50** as the encoder. Res2Net enhances the standard ResNet by constructing hierarchical residual-like connections within a single residual block, allowing it to represent features at multiple scales.
-   **Decoder:** The decoder consists of several upsampling blocks that progressively reconstruct the segmentation mask.
-   **Experimental Variant (CTO Stitch-ViT):** We also developed an experimental model that incorporates Vision Transformer (ViT) blocks into the decoder. The goal is to leverage the self-attention mechanism to better capture global context, which is potentially beneficial for segmenting long, continuous vessel structures.
-   **Deep Supervision:** The model employs deep supervision by generating predictions from multiple decoder stages (scales 1/4, 1/8, 1/16) and the edge attention module. This helps in learning robust features at different scales and alleviates the vanishing gradient problem during training.

#### **4.3. Semi-Supervised Learning: The Mean Teacher Method**
The Mean Teacher method is a powerful SSL technique.
-   **Student Model:** The primary model that is actively trained via gradient descent.
-   **Teacher Model:** A model with the same architecture as the student. Its weights are not trained directly but are an EMA of the student's weights. This makes the teacher's predictions more stable over time.
-   **Consistency Loss:** The student is encouraged to produce predictions on unlabeled data that are consistent with the teacher's predictions. We use a Mean Squared Error (MSE) loss between the student's and teacher's output masks for unlabeled samples.

#### **4.4. Loss Functions**
The total loss for the student model is a weighted sum of three components:
1.  **Binary Cross-Entropy (BCE) Loss:** A standard loss for binary classification tasks.
2.  **Dice Loss:** Directly optimizes the Dice Score (F1-score), which is a common metric for segmentation tasks as it is robust to class imbalance.
3.  **Boundary Loss:** A custom loss term that penalizes errors at the boundaries of the vessels. This encourages the model to produce sharper and more precise edges.
4.  **Deep Supervision Loss:** The total training loss is a weighted sum of the losses calculated at the main output and the auxiliary outputs, ensuring that intermediate layers also learn meaningful representations.

---

### **5. Implementation Details**

#### **5.1. Project Structure**
The codebase is organized into modules for clarity and maintainability.
```text
.
├── app.py              # GUI Application
├── config_stage1.json  # Configuration for Stage 1
├── data/               # All project data
├── logs/               # Training logs, curves, and images
├── models/             # Saved model checkpoints
└── src/                # Python source code
    ├── main.py         # Main training script
    ├── config.py       # Handles configuration loading
    ├── models/         # Model definitions (cto, cto_stitchvit)
    ├── training/       # Training logic (trainer, losses, mean_teacher)
    └── utils/          # Utility modules (metrics, logging, etc.)
```

#### **5.2. Software & Libraries Used**
- Python 3.9+
- PyTorch
- OpenCV
- Scikit-learn
- PyQt5 (for the GUI)
- Key libraries are listed in `requirements.txt`.

---

### **6. Experimental Results and Analysis**

#### **6.1. Evaluation Metrics**
Performance was measured using Dice Score, Intersection over Union (IoU), Precision, and Recall.
The Boundary F1 score was also used to specifically evaluate the accuracy of the segmented vessel edges.


#### **6.2. Quantitative Comparison**
The table below summarizes the final performance (Stage 2) of both **CTO-Net** and the experimental **CTO Stitch-ViT** across both the Human and Rat datasets.

| Model              | Dataset | Dice Score | IoU Score  | Boundary F1 |
| ------------------ | ------- | :--------: | :--------: | :---------: |
| **CTO-Net**        | Human   | **95.76%** | **91.88%** | **72.16%**  |
| (Res2Net-50)       | Rat     |  91.07%    |  83.64%    |   75.78%    |
| **CTO Stitch-ViT** | Human   |  92.43%    |  86.09%    |   59.52%    |
| (Experimental)     | Rat     | **91.99%** | **85.38%** | **85.14%**  |
*Table 1: Quantitative comparison of final models on validation sets.*

**Analysis of Quantitative Results:**
*   **Semi-Supervised Uplift:** In all experiments, the Stage 2 models demonstrated a consistent and significant performance improvement over their Stage 1 baselines, validating the effectiveness of the Mean Teacher approach for leveraging unlabeled data.
*   **CTO-Net on Human Dataset:** The standard `CTO-Net` shows outstanding performance on the Human dataset, outperforming the experimental Stitch-ViT model across all key metrics. This suggests its architecture is highly effective for the vessel structures in this dataset.
*   **Stitch-ViT on Rat Dataset:** The results reinforce our initial hypothesis. The `CTO Stitch-ViT` model shows a notable performance gain on the Rat dataset, especially in Boundary F1 score (85.14% vs 75.78%). This suggests its ability to capture global context is particularly advantageous for the more complex and variable vessel structures found in that data.

#### **6.3. Visual Analysis**
Visual inspection confirms the quantitative results. The final models (Stage 2) produce significantly cleaner and more coherent segmentations compared to their noisy Stage 1 counterparts.

**CTO-Net vs. CTO Stitch-ViT on Rat Dataset:**
!Rat Prediction Comparison
*Figure 2: Prediction comparison on the Rat dataset. Left: Ground Truth, Middle: CTO-Net, Right: CTO Stitch-ViT. The Stitch-ViT model captures finer boundary details, aligning with its higher Boundary F1 score.*

**CTO-Net on Human Dataset:**
!Human Prediction Comparison
*Figure 3: Prediction comparison on the Human dataset. The standard CTO-Net provides clean and accurate masks, outperforming the experimental model.*

**Visual Summary:**
- **Baseline vs. Final:** The consistency loss from the Mean Teacher method effectively acts as a regularizer, reducing noise and filling in gaps in the vessel structures for all final models. The improvement from Stage 1 to Stage 2 is visually dramatic.
- **Model Comparison:** On the Rat dataset, the predictions from `CTO Stitch-ViT` appear more confident and capture finer details along the vessel boundaries. On the Human dataset, `CTO-Net` provides clean and accurate masks that are superior to the Stitch-ViT variant.

---

### **7. Discussion**

#### **7.1. Project Successes**
1.  **Effective SSL:** The Mean Teacher pipeline successfully leveraged unlabeled data to significantly improve segmentation quality, validating the core hypothesis of this project.
2.  **High-Quality Segmentation:** The custom CTO-Net model with its Res2Net backbone and boundary-aware loss proved effective for this specific task.
3.  **End-to-End Pipeline:** The project resulted in a complete, usable system, from data preparation to interactive analysis.

#### **7.2. Limitations and Future Work**
1.  **Experimental Stitch-ViT:** The `cto_stitchvit` model is a preliminary exploration. More rigorous hyperparameter tuning and architectural adjustments are needed to determine if the added complexity of the transformer blocks provides a tangible benefit. Future work could explore more advanced ViT integrations.
2.  **Dataset-Specific Performance:** As noted, the benefits of `cto_stitchvit` appear to be dataset-dependent. Its advantages for the Rat dataset are clear, but it doesn't outperform the standard CTO-Net on the Human dataset, suggesting there is no one-size-fits-all solution.
3.  **Dependence on Pseudo-Labels:** The SSL stage relies on high-quality pseudo-labels from the teacher. If the initial baseline model is very poor, or if there is a large domain gap between labeled and unlabeled sets, the SSL training could be unstable. Future work could incorporate techniques to filter or weight pseudo-labels based on confidence.
4.  **Computational Cost:** The two-stage process is computationally intensive. Research into more efficient SSL methods or model distillation could reduce training time.

---

### **8. Key Learnings**
This project provided valuable hands-on experience in several key areas:
1.  **Semi-Supervised Learning:** Gained a deep, practical understanding of the Mean Teacher method, including implementing consistency loss and Exponential Moving Average (EMA) updates.
2.  **Advanced Model Architecture:** Learned to implement and integrate complex architectures like Res2Net and experiment with hybrid models involving Vision Transformers.
3.  **Loss Function Engineering:** Acquired experience in designing and balancing a composite loss function to optimize for specific segmentation characteristics.
4.  **Building a Full ML Pipeline:** Developed skills in creating an end-to-end workflow, from data preprocessing and training to building an interactive application.
5.  **Reproducibility:** Learned the importance of structured code, clear documentation, and external configuration files to ensure experiments are reproducible and extensible.

---

### **9. Conclusion**
This project successfully developed and validated a semi-supervised pipeline for lymphatic vessel segmentation. By combining a strong baseline architecture (CTO-Net) with the Mean Teacher method, we were able to leverage unlabeled video data to overcome the limitations of a small annotated dataset, producing high-quality segmentation masks. The final system is an effective end-to-end solution that demonstrates the power of semi-supervised learning for medical imaging tasks.

---

### **10. Appendix: How to Run the Project**
1.  **Setup:**
    ```bash
    # Create and activate a virtual environment
    python -m venv venv && source venv/bin/activate
    # Install dependencies
    pip install -r requirements.txt
    ```
2.  **Data Preparation:**
    - Place labeled data in `data/annotated/<type>/` and unlabeled videos in `data/video/<type>/`.
    - Run `tools/scripts/convert_json_to_mask.py` and `tools/scripts/extract_frames.py`.
3.  **Training:**
    ```bash
    # Run the full pipeline for the default CTO-Net
    python -m src.main all --visualize
    ```
4.  **Generate Evaluation Table:**
    ```bash
    python -m src.main visualize_eval --log-dir <path_to_log_directory>
    ```
5.  **Launch GUI:**
    ```bash
    python app.py
    ```
